{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comofd srm train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtr5-I3nLIVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense,Conv3D,MaxPooling3D,Dropout,Flatten,LeakyReLU,BatchNormalization,Conv2D,MaxPooling2D\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "tqdm.tqdm = tqdm.auto.tqdm\n",
        "import zipfile\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR9Yjvu6LKHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comofod='http://www.vcl.fer.hr/comofod/comofod_small.rar'\n",
        "zip_dir = tf.keras.utils.get_file('comofod_small.rar', origin=comofod)\n",
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!pip install patool\n",
        "import patoolib\n",
        "os.chdir(zip_dir_base)\n",
        "patoolib.extract_archive(\"comofod_small.rar\", outdir=zip_dir_base)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sK3B-CZLMUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auimg=glob.glob(zip_dir_base + '/CoMoFoD_small_v2/*_O_*')\n",
        "tpimg=glob.glob(zip_dir_base + '/CoMoFoD_small_v2/*_F_*')\n",
        "print(len(auimg))\n",
        "print(len(tpimg))\n",
        "\n",
        "target=zip_dir_base + '/Authentic'\n",
        "os.makedirs(target)\n",
        "target2=zip_dir_base + '/Tampered'\n",
        "os.makedirs(target2)\n",
        "\n",
        "for i in auimg:\n",
        "  shutil.move(i, target)\n",
        "  \n",
        "for i in tpimg:\n",
        "  shutil.move(i, target2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiuOoh3MLPLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=['Authentic', 'Tampered']\n",
        "for cl in classes:\n",
        "  img_path = os.path.join(zip_dir_base, cl)\n",
        "  images = glob.glob(img_path + '/*')\n",
        "  print(\"{}: {} Images\".format(cl, len(images)))\n",
        "  train, val = images[:round(len(images)*0.7)], images[round(len(images)*0.7):]\n",
        "\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(zip_dir_base, 'train', cl)):\n",
        "      os.makedirs(os.path.join(zip_dir_base, 'train', cl))\n",
        "    shutil.move(t, os.path.join(zip_dir_base, 'train', cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(zip_dir_base, 'val', cl)):\n",
        "      os.makedirs(os.path.join(zip_dir_base, 'val', cl))\n",
        "    shutil.move(v, os.path.join(zip_dir_base, 'val', cl))\n",
        "    \n",
        "train_dir = os.path.join(zip_dir_base, 'train')\n",
        "val_dir = os.path.join(zip_dir_base, 'val')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE4JBkQ3LUkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mfr(im):\n",
        "  medi=cv2.medianBlur(im,5)\n",
        "  medi2=cv2.medianBlur(medi,5)\n",
        "  medi=cv2.subtract(medi2, medi)\n",
        "  medi=medi[..., np.newaxis]\n",
        "  \n",
        "  avg = cv2.blur(im,(5,5))\n",
        "  avg = cv2.subtract(avg,im)\n",
        "  avg = avg[..., np.newaxis]\n",
        "  \n",
        "  k=np.array([[0,0,0,0,0], [0,-1,2,-1,0], [0,2,-4,2,0], [0,-1,2,-1,0], [0,0,0,0,0]], np.int32)\n",
        "  k1=k/4\n",
        "  srm1=cv2.filter2D(im, -1, k1)\n",
        "  srm1 = srm1[...,np.newaxis]\n",
        "  \n",
        "  k=np.array([[-1,2,-2,2,-1], [2,-6,8,-6,2], [-2,8,-12,8,-2], [2,-6,8,-6,2], [-1,2,-2,2,-1]], np.int32)\n",
        "  k2=k/12\n",
        "  srm2=cv2.filter2D(im, -1, k2)\n",
        "  srm2 = srm2[...,np.newaxis]\n",
        "  \n",
        "  k=np.array([[0,0,0,0,0], [0,0,0,0,0], [0,1,-2,1,0], [0,0,0,0,0], [0,0,0,0,0]], np.int32)\n",
        "  k3=k/2\n",
        "  srm3=cv2.filter2D(im, -1, k3)\n",
        "  srm3=srm3[...,np.newaxis]\n",
        "  \n",
        "  imge=np.concatenate((medi,avg), axis=2)\n",
        "  imge=np.concatenate((imge,srm1), axis=2)\n",
        "  imge=np.concatenate((imge,srm2), axis=2)\n",
        "  imge=np.concatenate((imge,srm3), axis=2)\n",
        "  \n",
        "  \n",
        "  imge=imge[..., np.newaxis]\n",
        "  return imge\n",
        "\n",
        "train_image_generator = ImageDataGenerator(preprocessing_function=mfr,\n",
        "                                           featurewise_center=True,\n",
        "                                           featurewise_std_normalization=True)\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=32, \n",
        "                                                           directory=train_dir, \n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(128,128,5),\n",
        "                                                           class_mode='sparse',\n",
        "                                                           color_mode='grayscale')\n",
        "val_image_generator = ImageDataGenerator(preprocessing_function=mfr,\n",
        "                                         featurewise_center=True,\n",
        "                                         featurewise_std_normalization=True)\n",
        "val_data_gen = val_image_generator.flow_from_directory(batch_size=32, \n",
        "                                                       directory=val_dir,\n",
        "                                                       \n",
        "                                                       target_size=(128,128,5),\n",
        "                                                       class_mode='sparse', \n",
        "                                                       color_mode='grayscale')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkdmCDGFLYPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ini=tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Conv3D(64,(1,1,5), strides=1,  activation='relu', input_shape=(128,128,5,1)))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(MaxPooling2D((3,3), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv3D(64,(3,3,1),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(LeakyReLU())\n",
        "model.add(MaxPooling3D((3,3,1),padding='same', strides=2))\n",
        "\n",
        "model.add(Conv3D(128,(3,3,1),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D((3,3,1),padding='same', strides=2))\n",
        "\n",
        "#model.add(LeakyReLU())\n",
        "model.add(Conv3D(256,(3,3,1),padding='same', activation='relu' ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D((3,3,1),padding='same', strides=2))\n",
        "#model.add(LeakyReLU())\n",
        "\n",
        "model.add(Conv3D(256,(3,3,1),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(LeakyReLU())\n",
        "model.add(MaxPooling3D((3,3,1),padding='same', strides=2))\n",
        "\n",
        "model.add(Conv3D(512,(3,3,1),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(LeakyReLU())\n",
        "model.add(MaxPooling3D((3,3,1),padding='same', strides=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2048, kernel_initializer=ini, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activation='relu'))\n",
        "\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(2048, kernel_initializer=ini, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activation='relu'))\n",
        "\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(2048, kernel_initializer=ini, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2048, kernel_initializer=ini, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activation='relu'))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlNJhP7HLbXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3mEsv_x3Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "                              train_data_gen,\n",
        "                              epochs=120,\n",
        "                              validation_data=val_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}